{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222de00f",
   "metadata": {},
   "source": [
    "**Actividad - Autoencoder para detección de fraude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db8b212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo cargado correctamente: 307511 filas y 122 columnas\n",
      "Tasa de incumplimiento: 8.07%\n",
      "Casos normales: 282686 | Casos incumplidos: 24825\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if '__file__' in globals():\n",
    "    ruta_base = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    ruta_base = os.getcwd()\n",
    "\n",
    "ruta_datos = os.path.join(ruta_base, \"..\", \"data\", \"application_train.csv\")\n",
    "datos = pd.read_csv(ruta_datos)\n",
    "\n",
    "filas, columnas = datos.shape\n",
    "tasa_incumplimiento = datos[\"TARGET\"].mean() * 100\n",
    "casos_normales = (datos[\"TARGET\"] == 0).sum()\n",
    "casos_incumplidos = (datos[\"TARGET\"] == 1).sum()\n",
    "\n",
    "print(f\"\\nArchivo cargado correctamente: {filas} filas y {columnas} columnas\")\n",
    "print(f\"Tasa de incumplimiento: {tasa_incumplimiento:.2f}%\")\n",
    "print(f\"Casos normales: {casos_normales} | Casos incumplidos: {casos_incumplidos}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a5830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variables creadas: 31\n",
      "Inconsistencias detectadas: 89958\n"
     ]
    }
   ],
   "source": [
    "# Selección de variables y creación de nuevas características\n",
    "\n",
    "# Variables de tiempo\n",
    "datos['EDAD'] = -datos['DAYS_BIRTH'] / 365\n",
    "datos['AÑOS_EMPLEADO'] = -datos['DAYS_EMPLOYED'] / 365\n",
    "datos['AÑOS_EMPLEADO'] = datos['AÑOS_EMPLEADO'].replace(1000.67, np.nan)\n",
    "datos['DIAS_CAMBIO_TELEFONO'] = -datos['DAYS_LAST_PHONE_CHANGE']\n",
    "datos['DIAS_PUBLICACION_ID'] = -datos['DAYS_ID_PUBLISH']\n",
    "\n",
    "# Ratios financieros\n",
    "datos['RATIO_CREDITO_INGRESO'] = datos['AMT_CREDIT'] / datos['AMT_INCOME_TOTAL']\n",
    "datos['RATIO_ANUALIDAD_INGRESO'] = datos['AMT_ANNUITY'] / datos['AMT_INCOME_TOTAL']\n",
    "datos['RATIO_ANUALIDAD_CREDITO'] = datos['AMT_ANNUITY'] / datos['AMT_CREDIT']\n",
    "datos['RATIO_BIENES_CREDITO'] = datos['AMT_GOODS_PRICE'] / datos['AMT_CREDIT']\n",
    "datos['INGRESO_PER_CAPITA'] = datos['AMT_INCOME_TOTAL'] / (datos['CNT_FAM_MEMBERS'] + 1)\n",
    "datos['CREDITO_PER_CAPITA'] = datos['AMT_CREDIT'] / (datos['CNT_FAM_MEMBERS'] + 1)\n",
    "\n",
    "# Detección de inconsistencias\n",
    "datos['INCONS_SCORE_INGRESO'] = 0\n",
    "mask1 = (datos['EXT_SOURCE_2'] < 0.3) & (datos['AMT_INCOME_TOTAL'] > datos['AMT_INCOME_TOTAL'].quantile(0.75))\n",
    "datos.loc[mask1, 'INCONS_SCORE_INGRESO'] = 1\n",
    "\n",
    "datos['INCONS_FAMILIA_INGRESO'] = 0\n",
    "mask2 = (datos['CNT_FAM_MEMBERS'] >= 4) & (datos['AMT_INCOME_TOTAL'] < datos['AMT_INCOME_TOTAL'].quantile(0.25))\n",
    "datos.loc[mask2, 'INCONS_FAMILIA_INGRESO'] = 1\n",
    "\n",
    "columnas_docs = [col for col in datos.columns if 'FLAG_DOCUMENT' in col]\n",
    "datos['TOTAL_DOCUMENTOS'] = datos[columnas_docs].sum(axis=1)\n",
    "datos['INCONS_DOCS_CREDITO'] = 0\n",
    "mask3 = (datos['TOTAL_DOCUMENTOS'] <= 2) & (datos['AMT_CREDIT'] > datos['AMT_CREDIT'].quantile(0.75))\n",
    "datos.loc[mask3, 'INCONS_DOCS_CREDITO'] = 1\n",
    "\n",
    "datos['TOTAL_INCONSISTENCIAS'] = (datos['INCONS_SCORE_INGRESO'] + \n",
    "                                   datos['INCONS_FAMILIA_INGRESO'] + \n",
    "                                   datos['INCONS_DOCS_CREDITO'])\n",
    "\n",
    "# Variables de círculo social\n",
    "datos['DEFAULTS_SOCIALES'] = (datos['DEF_30_CNT_SOCIAL_CIRCLE'].fillna(0) + \n",
    "                               datos['DEF_60_CNT_SOCIAL_CIRCLE'].fillna(0))\n",
    "datos['OBSERVACIONES_SOCIALES'] = (datos['OBS_30_CNT_SOCIAL_CIRCLE'].fillna(0) + \n",
    "                                    datos['OBS_60_CNT_SOCIAL_CIRCLE'].fillna(0))\n",
    "datos['TASA_DEFAULT_SOCIAL'] = datos['DEFAULTS_SOCIALES'] / (datos['OBSERVACIONES_SOCIALES'] + 1)\n",
    "datos['TIENE_CIRCULO_RIESGOSO'] = (datos['DEFAULTS_SOCIALES'] > 0).astype(int)\n",
    "\n",
    "# Variables de estabilidad\n",
    "datos['TIENE_AUTO'] = (~datos['OWN_CAR_AGE'].isna()).astype(int)\n",
    "datos['TIENE_PROPIEDAD'] = (datos['FLAG_OWN_REALTY'] == 'Y').astype(int)\n",
    "datos['CAMBIO_TELEFONO_RECIENTE'] = (datos['DIAS_CAMBIO_TELEFONO'] < 180).astype(int)\n",
    "datos['PUBLICACION_ID_RECIENTE'] = (datos['DIAS_PUBLICACION_ID'] < 365).astype(int)\n",
    "\n",
    "datos['SCORE_ESTABILIDAD'] = (datos['TIENE_AUTO'] + datos['TIENE_PROPIEDAD'] + \n",
    "                               (1 - datos['CAMBIO_TELEFONO_RECIENTE']) + \n",
    "                               (1 - datos['PUBLICACION_ID_RECIENTE']))\n",
    "\n",
    "# Interacciones y flags de riesgo\n",
    "datos['RATIO_EDAD_EMPLEO'] = datos['EDAD'] / (datos['AÑOS_EMPLEADO'] + 1)\n",
    "datos['SOBREENDEUDAMIENTO'] = (datos['RATIO_CREDITO_INGRESO'] > 8).astype(int)\n",
    "datos['JOVEN_CREDITO_ALTO'] = ((datos['EDAD'] < 25) & (datos['AMT_CREDIT'] > 500000)).astype(int)\n",
    "datos['EMPLEO_NUEVO_CREDITO_ALTO'] = ((datos['AÑOS_EMPLEADO'] < 0.5) & (datos['AMT_CREDIT'] > 300000)).astype(int)\n",
    "\n",
    "columnas_bureau = [col for col in datos.columns if 'AMT_REQ_CREDIT_BUREAU' in col]\n",
    "datos['TOTAL_CONSULTAS_BUREAU'] = datos[columnas_bureau].sum(axis=1)\n",
    "datos['CONSULTAS_EXCESIVAS'] = (datos['TOTAL_CONSULTAS_BUREAU'] > 5).astype(int)\n",
    "\n",
    "# Lista de variables seleccionadas\n",
    "variables_seleccionadas = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY',\n",
    "    'RATIO_CREDITO_INGRESO', 'RATIO_ANUALIDAD_INGRESO', 'RATIO_ANUALIDAD_CREDITO',\n",
    "    'INGRESO_PER_CAPITA', 'CREDITO_PER_CAPITA',\n",
    "    'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "    'EDAD', 'AÑOS_EMPLEADO', 'DAYS_REGISTRATION', 'RATIO_EDAD_EMPLEO',\n",
    "    'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'TASA_DEFAULT_SOCIAL', 'TIENE_CIRCULO_RIESGOSO',\n",
    "    'REGION_RATING_CLIENT', 'REG_CITY_NOT_WORK_CITY',\n",
    "    'TOTAL_DOCUMENTOS', 'SCORE_ESTABILIDAD',\n",
    "    'TOTAL_INCONSISTENCIAS', 'INCONS_SCORE_INGRESO', \n",
    "    'INCONS_FAMILIA_INGRESO', 'INCONS_DOCS_CREDITO',\n",
    "    'SOBREENDEUDAMIENTO', 'JOVEN_CREDITO_ALTO', 'EMPLEO_NUEVO_CREDITO_ALTO', \n",
    "    'CONSULTAS_EXCESIVAS', 'CAMBIO_TELEFONO_RECIENTE'\n",
    "]\n",
    "\n",
    "print(f\"\\nVariables creadas: {len(variables_seleccionadas)}\")\n",
    "print(f\"Inconsistencias detectadas: {datos['TOTAL_INCONSISTENCIAS'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc664c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datos preparados:\n",
      "Entrenamiento: (226148, 31)\n",
      "Validacion: (56538, 31)\n",
      "Dataset completo: (307511, 31)\n"
     ]
    }
   ],
   "source": [
    "# PREPARACION DE DATOS\n",
    "\n",
    "# Crear dataset de trabajo\n",
    "datos_trabajo = datos[variables_seleccionadas + ['TARGET', 'SK_ID_CURR']].copy()\n",
    "\n",
    "# Imputar valores nulos\n",
    "for col in variables_seleccionadas:\n",
    "    if datos_trabajo[col].isnull().sum() > 0:\n",
    "        if col in ['EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "            datos_trabajo[col].fillna(datos_trabajo[col].median(), inplace=True)\n",
    "        else:\n",
    "            datos_trabajo[col].fillna(0, inplace=True)\n",
    "\n",
    "# Separar datos normales para entrenar el autoencoder\n",
    "datos_normales = datos_trabajo[datos_trabajo['TARGET'] == 0].copy()\n",
    "X_normales = datos_normales[variables_seleccionadas].values\n",
    "X_todos = datos_trabajo[variables_seleccionadas].values\n",
    "y_todos = datos_trabajo['TARGET'].values\n",
    "\n",
    "# Dividir en entrenamiento y validacion\n",
    "X_entrenamiento, X_validacion = train_test_split(X_normales, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar datos\n",
    "escalador = RobustScaler()\n",
    "X_entrenamiento_escalado = escalador.fit_transform(X_entrenamiento)\n",
    "X_validacion_escalado = escalador.transform(X_validacion)\n",
    "X_todos_escalado = escalador.transform(X_todos)\n",
    "\n",
    "print(f\"\\nDatos preparados:\")\n",
    "print(f\"Entrenamiento: {X_entrenamiento.shape}\")\n",
    "print(f\"Validacion: {X_validacion.shape}\")\n",
    "print(f\"Dataset completo: {X_todos.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d346965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo creado con 31 variables de entrada\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,999</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │         \u001b[38;5;34m3,999\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,727</span> (123.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,727\u001b[0m (123.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,831</span> (120.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,831\u001b[0m (120.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando autoencoder...\n",
      "Epoch 1/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 1.0915 - mse: 78.0307 - val_loss: 0.3474 - val_mse: 1.3257 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.4019 - mse: 1.7693 - val_loss: 0.3317 - val_mse: 1.1999 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3725 - mse: 1.2415 - val_loss: 0.2688 - val_mse: 0.3020 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3484 - mse: 1.0631 - val_loss: 0.2617 - val_mse: 0.3571 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3370 - mse: 1.0091 - val_loss: 0.2415 - val_mse: 0.2598 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3361 - mse: 0.9920 - val_loss: 0.2240 - val_mse: 0.2108 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3261 - mse: 0.8848 - val_loss: 0.2217 - val_mse: 0.2063 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3252 - mse: 0.9076 - val_loss: 0.2325 - val_mse: 0.2366 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3272 - mse: 0.9505 - val_loss: 0.2238 - val_mse: 0.2165 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3199 - mse: 0.8898 - val_loss: 0.2330 - val_mse: 0.2682 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.3205 - mse: 0.9288 - val_loss: 0.2226 - val_mse: 0.2171 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3153 - mse: 0.8502 - val_loss: 0.2315 - val_mse: 0.2531 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3205 - mse: 0.9272 - val_loss: 0.2192 - val_mse: 0.2059 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3163 - mse: 0.9232 - val_loss: 0.2373 - val_mse: 0.3150 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3131 - mse: 0.8593 - val_loss: 0.2260 - val_mse: 0.2199 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3113 - mse: 0.8674 - val_loss: 0.2115 - val_mse: 0.1950 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3127 - mse: 0.9058 - val_loss: 0.2233 - val_mse: 0.2321 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3125 - mse: 0.9253 - val_loss: 0.2123 - val_mse: 0.1970 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3072 - mse: 0.9322 - val_loss: 0.2225 - val_mse: 0.2286 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3050 - mse: 0.9346 - val_loss: 0.2034 - val_mse: 0.1885 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3053 - mse: 0.9223 - val_loss: 0.2127 - val_mse: 0.2063 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3018 - mse: 0.8703 - val_loss: 0.2246 - val_mse: 0.2435 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.3043 - mse: 0.8712 - val_loss: 0.2119 - val_mse: 0.2060 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3017 - mse: 0.8856 - val_loss: 0.2100 - val_mse: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3030 - mse: 0.9473 - val_loss: 0.2092 - val_mse: 0.1946 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3015 - mse: 0.8869 - val_loss: 0.2283 - val_mse: 0.2500 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3062 - mse: 0.9707 - val_loss: 0.2004 - val_mse: 0.1858 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3097 - mse: 0.9889 - val_loss: 0.2248 - val_mse: 0.2729 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.2989 - mse: 0.8203 - val_loss: 0.2082 - val_mse: 0.1958 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3019 - mse: 0.8682 - val_loss: 0.2208 - val_mse: 0.2618 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3114 - mse: 1.0355 - val_loss: 0.2061 - val_mse: 0.1934 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2964 - mse: 0.8153 - val_loss: 0.2044 - val_mse: 0.1929 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3064 - mse: 0.9799 - val_loss: 0.2021 - val_mse: 0.1912 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m882/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3028 - mse: 0.9157\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3028 - mse: 0.9158 - val_loss: 0.2017 - val_mse: 0.1855 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.2995 - mse: 0.8329 - val_loss: 0.1963 - val_mse: 0.1824 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.2964 - mse: 0.8426 - val_loss: 0.1978 - val_mse: 0.1859 - learning_rate: 5.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3025 - mse: 0.9160 - val_loss: 0.2108 - val_mse: 0.2168 - learning_rate: 5.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3035 - mse: 0.9778 - val_loss: 0.1962 - val_mse: 0.1837 - learning_rate: 5.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.2940 - mse: 0.8122 - val_loss: 0.1996 - val_mse: 0.1842 - learning_rate: 5.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3044 - mse: 0.9400 - val_loss: 0.2058 - val_mse: 0.1992 - learning_rate: 5.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3014 - mse: 0.9310 - val_loss: 0.2001 - val_mse: 0.1876 - learning_rate: 5.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3010 - mse: 0.9415 - val_loss: 0.2010 - val_mse: 0.1875 - learning_rate: 5.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.2982 - mse: 0.9053 - val_loss: 0.2105 - val_mse: 0.2146 - learning_rate: 5.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.2946 - mse: 0.8604 - val_loss: 0.2030 - val_mse: 0.1916 - learning_rate: 5.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m873/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2969 - mse: 0.8929\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2969 - mse: 0.8931 - val_loss: 0.2073 - val_mse: 0.2089 - learning_rate: 5.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2971 - mse: 0.9026 - val_loss: 0.2114 - val_mse: 0.2291 - learning_rate: 2.5000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2992 - mse: 0.8968 - val_loss: 0.2102 - val_mse: 0.2217 - learning_rate: 2.5000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2979 - mse: 0.9239 - val_loss: 0.1990 - val_mse: 0.1898 - learning_rate: 2.5000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.2959 - mse: 0.8695 - val_loss: 0.1983 - val_mse: 0.1885 - learning_rate: 2.5000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2944 - mse: 0.8590 - val_loss: 0.2024 - val_mse: 0.1911 - learning_rate: 2.5000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2981 - mse: 0.8880 - val_loss: 0.1950 - val_mse: 0.1823 - learning_rate: 2.5000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2977 - mse: 0.9142 - val_loss: 0.1993 - val_mse: 0.1869 - learning_rate: 2.5000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.3036 - mse: 0.9704 - val_loss: 0.1931 - val_mse: 0.1814 - learning_rate: 2.5000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2963 - mse: 0.8758 - val_loss: 0.2069 - val_mse: 0.2088 - learning_rate: 2.5000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2908 - mse: 0.8141 - val_loss: 0.2021 - val_mse: 0.1986 - learning_rate: 2.5000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2939 - mse: 0.8329 - val_loss: 0.1982 - val_mse: 0.1873 - learning_rate: 2.5000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2874 - mse: 0.7863 - val_loss: 0.1978 - val_mse: 0.1861 - learning_rate: 2.5000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2955 - mse: 0.8885 - val_loss: 0.2045 - val_mse: 0.2051 - learning_rate: 2.5000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2994 - mse: 0.9572 - val_loss: 0.2040 - val_mse: 0.1958 - learning_rate: 2.5000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m881/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2971 - mse: 0.8838\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2971 - mse: 0.8840 - val_loss: 0.2044 - val_mse: 0.1982 - learning_rate: 2.5000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2945 - mse: 0.8705 - val_loss: 0.1959 - val_mse: 0.1848 - learning_rate: 1.2500e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2979 - mse: 0.8988 - val_loss: 0.1965 - val_mse: 0.1882 - learning_rate: 1.2500e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.2907 - mse: 0.8346 - val_loss: 0.1991 - val_mse: 0.1917 - learning_rate: 1.2500e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2924 - mse: 0.8484 - val_loss: 0.1947 - val_mse: 0.1837 - learning_rate: 1.2500e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2964 - mse: 0.9287 - val_loss: 0.1961 - val_mse: 0.1853 - learning_rate: 1.2500e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2949 - mse: 0.8554 - val_loss: 0.1990 - val_mse: 0.1897 - learning_rate: 1.2500e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m880/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2976 - mse: 0.9350\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2976 - mse: 0.9347 - val_loss: 0.1969 - val_mse: 0.1863 - learning_rate: 1.2500e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.2902 - mse: 0.8602 - val_loss: 0.1996 - val_mse: 0.1935 - learning_rate: 6.2500e-05\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "\n",
      "Entrenamiento completado en 68 epocas\n",
      "Loss final entrenamiento: 0.2933\n",
      "Loss final validacion: 0.1996\n"
     ]
    }
   ],
   "source": [
    "# CONSTRUCCION Y ENTRENAMIENTO DEL AUTOENCODER\n",
    "\n",
    "# Definir arquitectura del autoencoder\n",
    "dimension_entrada = X_entrenamiento_escalado.shape[1]\n",
    "\n",
    "# Capa de entrada\n",
    "entrada = Input(shape=(dimension_entrada,))\n",
    "\n",
    "# Encoder: comprime la informacion\n",
    "x = Dense(128, activation='relu')(entrada)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Capa latente (representacion comprimida)\n",
    "codigo = Dense(16, activation='relu')(x)\n",
    "\n",
    "# Decoder: reconstruye la informacion\n",
    "x = Dense(32, activation='relu')(codigo)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Capa de salida\n",
    "salida = Dense(dimension_entrada, activation='linear')(x)\n",
    "\n",
    "# Crear y compilar el modelo\n",
    "autoencoder = Model(entrada, salida)\n",
    "autoencoder.compile(optimizer='adam', loss='mae', metrics=['mse'])\n",
    "\n",
    "print(f\"\\nModelo creado con {dimension_entrada} variables de entrada\")\n",
    "autoencoder.summary()\n",
    "\n",
    "# Configurar callbacks para el entrenamiento\n",
    "parada_temprana = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
    "reducir_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, verbose=1)\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\nEntrenando autoencoder...\")\n",
    "historial = autoencoder.fit(\n",
    "    X_entrenamiento_escalado, X_entrenamiento_escalado,\n",
    "    epochs=150,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_validacion_escalado, X_validacion_escalado),\n",
    "    callbacks=[parada_temprana, reducir_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nEntrenamiento completado en {len(historial.history['loss'])} epocas\")\n",
    "print(f\"Loss final entrenamiento: {historial.history['loss'][-1]:.4f}\")\n",
    "print(f\"Loss final validacion: {historial.history['val_loss'][-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
